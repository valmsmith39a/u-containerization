Deployment 
  Environment 
  Dependencies
  App Files

Manually not scalable 

Production/Deployment different in unintended ways

Bundle application with environment and deploy as a unit 

Virtual Machines/Containers 

Environment/Dependencies/App Files deployed as a unit 

Containers: lightweight way of deploying env/dep/files as a unit

Both can be used to horizontally scale an application

Multiple containers/VMs can be run on same machine but containers funning on same machine share same low-level operating system kernel. 

Container:
  OS level virtualization allows run multiple isolated proccesses in parallel. 

  Container is an isolated process consisting of: 
    1. application code 
    2. required dependencies
    3. necessary runtime environment to run application

  Each container is an independent component that can run on it's own and moved from environment to environment. 
  
  Benefits of containers
    Easier for deveopers to create/deploy/run apps
    Containers share single kernel and application libraries
    Less system overhead compared to VMs

How to create containers? 

Several platforms (Container runtime/engines) allow to create containers 

Ex Docker, CRI-O, OpenVZ

Containers are a light-weight option to bundle application with it's environment. 

Virtual Machines 
  Simulate a complete machine 
  Own operating system 
  Not tied to a single executable

  App App  App 
  OS  OS   OS
  Hypervisor
  Infrastructure

  VM is like a complete computer 
    Own operating system and virtual hardware 
    Single physical machine can run many virutal machines 
    Virtualize an entire machine, but resource-intensive

VMs managed on a host machine: 
Host operating system runs the VMs using a hypervisor (creates/manages the VMs)

Containers managed on a host machine:
  Containers bundle application with dependencies. 
  Containers do not have separate Operating System or virtualized hardware. 
  Containers share a single operating system kernel.
  Containers are managed by a container manager 

How to create VMs? 
  use one of the following Hypervisors
    Microsoft Hyper-V
    Oracle VM VirtualBox
    VMWare
    Parallels Desktop

  or Cloud service providers offer ability to create VM on their infrastructure
    AWS EC2
    GCP Compute Engines
    Azure Virutal Machines 

Problem with VMs
  VMs work well for scaling applications they can be resource intensive because they viertualize an entire machine.

Containers are light-weight becaues they run on the shared host OS instead of virtualizing an enitrre OS and system's resources.No operating systems or virtual hardware in container model. 

Recap differences

1. Underlying OS
  VMs: One host, many VMs. Each VM has it's own OS
  Containers: Shared host, many guests

2. Management software
  VMs: hypervisor (ex VirtualBox)
  C: container manager (ex Docker)

3. Resource requirements
  VMs: heavy
  C: light

4. Speed
  VMs: slower
  C: faster

5. Flexibility in chose of OS s/w and h/w configuration
  VMs: total flexibility
  C: limited flexibility

6. Resource constraint
  VMs: Yes. Cannot use h/w resources beyond what is allocated while creating VM. 
  C: No resource constraint. use as much of a resource as host's kernel scheduler allows 

Summary of Benefits of using Containers vs VMs

1. Size: Containers much smaller than VMs, run as isolated proccesses vs virtualized hardware. VMs can be in GBs, while containers are in MBs. 

2. Speed: Virtual Machines can be slow to boot, takes minutes to launch. Container spawns more quickly, typically within seconds. 

3. Composability: Containers designed to be programmatically built and defined as source code. VMs are replicas of conventional computer system. 

***Shared kernels enable containers to be lightweight***

Docker
Open-sourced container runtime tool that helps to build, test and run containers. Container system and a company. 

Can use Docer to create both Linux and Windows kernels. 

Install Docker on local machine (Docker Desktop - cmomand line utility)

Docker: open source container platform 

Can run Linux and Windows containers

Docker image is a private file stystem just for your container. It provides all the files and code your container needs. 

Start a container based on image built in previous step 

Running a container launches application with private resources, securely isolated from rest of machine. 

docker run -d -p 80:80 docker/getting-started
-d - run the container in detached mode (in the background)

-p 80:80 - map port 80 of the host to port 80 in the container

docker/getting-started - the image to use

You can combine single character flags to shorten the full command. As an example, the command above could be written as:

docker run -dp 80:80 docker/getting-started

***

Following command will fetch an image and create and run a container 

docker run -d -p 80:80 docker/getting-started

  fetches an image docker/getting-started, creates and runs a continaer. 

  Can access this container using http://localhost:80 in browser 

Docker vocab

  Docker engine: Software that runs Docker locally

    Docker DAEMON: manages images, containers, networks and volumes 

    API

    Docker Client: command line or desktop app 

  Docker Image: Instructions for creating a container, immutable template for a container. 
    Image has all instructions needed for creating a container 

    Single image can be used for creating multiple containers 

    Images stored in Docker Registries 

  Docker Container: is a running instance of the image 

  Docker Registry: Where images are stored 
  
    Can be public or private 

    Docker Hub - public registry 

  Volumes:     
    Containers not designed for persistent data 
    
    Started / Stopped as demand requires 
    
    Volumes attached to containers to hold the data 

    Used to store and hold data across containers 
    
 Review:

 Docker Engine: application that consists of 1) daemon, 2) api, 3) client

  Docker daemon: server that manages the images, containers, networks and volumes

  Docker client: user interface for Docker. Client is command line interface (CLI) 

  Client communicates with the daemon through the command line API 

  Use Docker Engine to create and run containers 

Docker Image: instructions for creating a container. Includes file system and parameters used for the container 

  Images comprised of multiple layers. Each layer contains specific software 

  Can create a custom Docker image for specific application. 

  Ex. standardized parent image as base layer 

  Parent image - file system of a particular operating system (ex Ubuntu 18.04) Then add additional layer to the image. 

  Can add application files to the additional layer. 

  Can add multiple layers and distribute application files across different layers. 


Docker Container: runnable instance of an image; an implementation of the Docker image. Multiple containers can be created from the sam eimage 

Docker Registry: Docker images can be stored and distributed using a Docker registry. 

Docker Hub: public registry with many images to use 

Summary:

Docker Engine: application consisting of daemon, API, client 

  Docker Daemon: server managing images, containers, networks, and volumes

  Docker Client: command line interface 

Docker Image: instructions for creating a container (file system/parameters)

Docker Container: implementation of  Docker image; runnable instance of a Docker Image 

Docker Registry: Repository of Docker images  

**

To create a container: 
  
  Dockerfile -> Docker Image -> Docker Container 

  1. Write a Dockerfile 

    text document containing commands user would execute on command line to assemble an image. 

    specify the necessary environments and dependencies. 

    Ex 
    # Pull the "tomcat" image. The community maintains this image. 
FROM tomcat 
# Copy all files present in the current folder to the "/usr/local/tomcat/webapps"  folder 
COPY ./*.* /usr/local/tomcat/webappsa

  Every time create a container, it will have tomcat web server installed 

  All contents of current directory copied to /usr/local/tomcat/webapps folder of eacy container 

Build an Image: 

  docker build: build an image from the Dockerfile 

  execute the command from same directory where dockerfile is present 

  # This command will look for a Dockerfile in the `pwd`, and create myImage
  docker build --tag myImage [OPTIONS] path_where_to_store_the_image

  can store images online at DockerHub so that anyone can "pull" the image on any other machine, anytime 

  docker pull tomcat:latest 

Create an run a Container:

  After creating an image can use it to create as many Containers as want on any platform. Each container has the same environment/dependencies to run a copy of the application. 

# creates and runs a new container:
docker run --name myContainer myImage 

Summary:

Create a container: Dockerfile, Docker Image, Docker Container 

  1. Write a Dockerfile: text document with commands executed on command line to assemble the image.

  2. Build the image: build the image from the Dockerfile 
    docker build --tag myImage [OPTIONS] path_to_where_to_store_image

    Can pull container from registry: docker pull tomcat:lastest

  3. Create and run a Container: use image to create the container 

    docker run --name myContainer myImage 

***To create a container, create a Dockerfile to create a Docker Image and use Docker Image to create a Docker Container***

Docker Hub: largest Docker image registry

Python images, flask, running databases etc 

**

Docker text files: text files to define Docker images
  Contain commands used to define a source or parent image
  Copy files to the image 
  Install software on the image 
  Define the application 

Dockerfile -> docker build -> Docker Image 
Docker Image -> docker run -> Docker Container 


Dockerfile Command Glossary


Dockerfile comments start with #.
FROM defines source image upon which the image will be based.
COPY copies files to the image.
WORKDIR defines the working directory for other commands.
RUN is used to run commands other than the main executable.
ENTRYPOINT is used to define the main executable.

REVIEW
Docker Container: ephemeral application that is deployed as one unit 

Docker Image: application and it's dependencies

Dockerfile: Instructions on how to translate application code into an image 

Docker Registry: application that stores/lets you distribute Docker images 

Create a Dockerfile
Build a Dockerfile to create the Docker Image 
Run the Docker Image to create and start the Docker Container 

Lesson Summary 
Containers/Docker container system 
Bundling applications and dependencies 
Docker files are used to define Docker Images and Docker Images are run to instantiate containers.

Build and run containers from these files.

Next: Deploying Containers

**
DEPLOYMENT:

Deployment: the process of making the application run on the production environment (group of servers/virtual machines/containers on-premise/on-cloud). 

Deploying containerized applications 

Container orchestration with Kubernetes 

Kubernetes cluster 

Continuous Integration and Continuous Delivery 

Docker containers: tool to bundle your application with it's environment and dependencies 

Deploy your container to the cloud 

Container orchestration: 
  manage scaling: new container instances/shutting them down - use a container orchestration service. 

  orchestration service
    auto-scaling of containers 
    balance loads 
    check health 
    manage container's lifecycle (instantiatig, scaling on multiple hosts, configuring, networking etc)

CI/CD pipeline: set of software deployment practice that automatically prepares code and deploys it into the production environment. 

  Automated code compilation 
  Running tests 
  Formulating a build 
  Deploying the build to the target infrastructure (servers)

2 stages:
  Continuous Integration (Build): automated compile, test and build processes
  Continuous Delivery (Deploy): deploy application into production environment (automatic deployment for small incremental/frequent releases). 

Continuous Integration: Automatically building and testing the code when changes made 

Continuous Delivery: CI combined with automated deployment 

CI/CD pipeline: has one end associated with a shared repository containing application code. Other is connected to cloud infrastructure. 

Objectives:
  Deploy containerized app: AWS' Kubernetes service: EKS
  Set up continuous integration: AWS CodeBuild
  Create continuous delivery pipeline: AWS CodePipeline 

Kubernetes:

  Manage containers as a group 

Vertical Scaling: increase the resources of the machine 
  difficult to scale up/down as demand changes 
  larger machines more expensive than similar resources spread across smaller machines. 

Horizontal Scaling: run multiple instances of the same application across multiple machines, increasing or decreasing the number as demand changes 

  advantages of containerized applications 

  run multiple copies of the same images at once

Kubernetes: container orchestration 

Review:

Vertical Scaling: increase host machine's hardware resources on which container is running. 
  Challenging to scale up/down as demand changes 
  Larger host machines more expensive than smaller machines - loss if machine underutilized. 

Horizontal Scaling: run multiple instances of the same application across multiple machines 
  run multiple containers based on the same image 

Previously containerized application locally;

  limitations:
    scaling: cannot automatically scale up/down resources (number of containers) or application usage requirements based on incoming traffic 

    updates: managing patch/update in application that has been scaled up horizontally on multiple hosts

    elasticity: local computers / on-premise servers may not have the hardware requirements for running many computers in parallel 

Kubernetes handles autoscaling problems 
Elastic (unlimited) resources on the cloud handles elasticity problems 

Kubernetes:
  one of most popular orchestration system for containers (developed by Google) 

  automate many of the manual operations of deployment / scaling of containerized application. 

  benefits:
    ease of scaling container instances up / down to meet varying demands 

    balance loads, perform health checks 

    helps setting up inter-container communication (networking) 

    high available architecture

    auto-scaling

    rich econsystem 

    service discovery 

    container health management 

    secrets and configuration management 

 Kubernetes:

  Kubernetes cluster: group of machines running Kubernetes 

  Master: system which controls a Kubernetes cluster. Interact with master when communicate with a cluster. 
    api, scheduler, management daemon

  Nodes: Machines in a cluster - virtual/physical 

  Pods: Smallest unit in a cluster. logical group of containers on a node that runs a particular application. 
    Pod has one or more containers, shared resources, unique IP address 

    Containers within a pod share namespace/filesystem volumes 

    Pods not persisten - brought up/down during scaling

 Kubernetes Cluster Architecture: 

  Several node machines for running containerized applications. 

  Master manages the nodes 

  Each node runs multiple pods (groups of containers) 

  Each node has a container runtime (Docker) installed on it 

  Nodes managed by Master system. Each node *must* have a container runtime such as Docker 

  A node can host multiple Pods. 

  The Pods run independent modules of an application 

  Pods replicated across multiple nodes 

Reliability:
  Pods run specific module of an application (App A, B...)

  Pods not attached to a specific node. Multiple nodes host similar Pods 

  Mitigates single point of failure to provide high availability.

All pods running the same application share storage resources. All containers within pod share namespaces/filesystem volumnes. 

Volumes attached to pods to store data. 

Kubernetes service: persistent way to communicate with ephemeral pods - higher level service abstraction provided. 

Review:

Kubernetes Cluster: group of machines (nodes) running Kubernetes

Nodes: Machines in a cluster 

Master: system to control the Kubernetes cluster 

Pods: Groups of containers (smallest unit in a cluster), shared storage resources, unique IP address. 

App service: interact with pods. Ex App A service interacts with all Pods running App A. Those pods can be on different nodes. 

Can attach Volume to those pods 

**
Container: abstraction of application and it's dependencies 

Kubernetes pod: abstraction of multiple containers 

Kubernetes Service: abstraction of pods and their interfaces 

Wrap pods as a service because don't care when pods are destroyed 

** 
High level Kubernetes work flow 

1. Create a Kubernetes Cluster 

2. Deploy an application into the cluster

3. Expose application ports 

4. Scaling an application 

5. Updating an application 

How to set up a Kubernetes cluster? 
1. Set up a local cluster (Docker Desktop).
2. Provision a cloud cluster.

***
Master system is a control plane comprising: 
  kube-controller-manager
  kube-apiserver: api server exposing Kubernets API
    HTTP API allows end-users, cluster, external components to communicate
    Allows querying/manipulating state of API objects (Pods, Namespaces, ConfgMaps/Events)
  etcd: key-value store of cluster data 
  kube-scheduler: monitors pods, assigns worker node to newly created pods 
  cloud-controller-manager: embeds control logic/link cluster to cloud provider's API 

Node: 
  pod
  kube-proxy: mantains network rules on nodes for network communication to pods from network session inside/outside cluster 
  kubelet: agent on each node that tracks containers are running in correct pod.  container runtime: ex Docker, to run the containers 



Control plane: manages worker nodes and Pods in a cluster 
  decides when to start up a new pod or schedule events 


